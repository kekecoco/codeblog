#### PHP导入大量数据到MySQL

> 移动广告的统计数据是从Redis导入到文件中的，对原始数据的利用一直没有比较好的方式。
>
> 现在需要对这些原始数据进行查询，利用文件进行肯定不行，需要将文件中的数据导入到MySQL中进行查询。

##### 0X01 实际情况说明

1. 无法直接通过Redis直接导入数据到MySQL中。由于Redis中的统计数据量非常大，而且是通过定时任务脚本导出数据，如果将这些数据直接导入MySQL中，势必给数据库造成非常大而且持久的压力。这种情况非常容易产生雪崩，致使整个服务崩溃。
2. 原始数据文件内容是JSON格式的数据，没法利用文件进行查询。
3. 将文件中的内容处理为一个个字段导入到数据库，需要注意效率和内存的问题。每个文件大概2G~3G，利用PHP处理，必须要保证PHP的安全，不然非常容易内存泄漏。
4. PHP处理完的数据导入到MySQL时，需要注意MySQL的负载情况，批量导入很容易导致MySQL负载过高。

##### 0X02 解决方案

1. PHP通过内置流处理函数，利用生成器将大型文件的内容读入内存，然后处理JSON格式的数据。
2. 处理完后的JSON格式的数据然后再写入到另一个文件中。
3. 利用MySQL提供的DATA LOAD INFILE 语句高效导入文件内容到数据表中。

##### 0X03 方案说明

1. PHP提供了流式文件处理的扩展Streams，利用Streams提供的函数读入文件的一行进行处理。相类似的函数还有文件函数中的fgets()，实际测试fgets()函数要慢于流式处理的函数streams_get_line()。
2. PHP生成器可以有效保证在读入文件数据时，PHP的内存占用是健康的，不至于导致PHP内存泄漏。
3. 读入原始文件JSON数据，不能直接插入数据库，这样大批量的插入会导致数据库负载过高而且效率极低。所以采用将处理过的数据生成为约定格式的数据文件。
4. 2G~3G的文件生成数据文件，大概需要900秒(15分钟)的时间。这个时间可以接受。
5. 生成的数据文件，是对应的数据库中每个字段的具体值。考虑到有数据重复，在导入数据库的过程中需要使用IGNORE字段，避免重复保存影响整个导入进程。
6. 导入生成的数据文件，2G~3G产生的数据大概有700万左右，利用Load data infile 导入数据库大概需要100s左右。
7. Load data infile是MySQL官方提供的高效导入文件数据到数据库的语句，比source语句要高效的多。
8. 总体的耗费时间大概需要16分钟左右，由于所需数据不需要及时导入，这个效率基本可以接受。